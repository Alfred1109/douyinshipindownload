"""
æµè§ˆå™¨è‡ªåŠ¨åŒ–è·å–å™¨ - ä½¿ç”¨ Playwright æ¨¡æ‹ŸçœŸå®æµè§ˆå™¨
å®Œå…¨æ¨¡æ‹Ÿäººçš„è¡Œä¸ºï¼Œè‡ªåŠ¨è·å–è§†é¢‘/éŸ³é¢‘èµ„æº
"""
import asyncio
import logging
import re
from pathlib import Path
from typing import Optional, Tuple
import json

from app.config import settings
from app.models.schemas import VideoInfo

logger = logging.getLogger(__name__)


class BrowserFetcher:
    """
    æµè§ˆå™¨è‡ªåŠ¨åŒ–è·å–å™¨
    
    ä½¿ç”¨ Playwright æ¨¡æ‹ŸçœŸå®æµè§ˆå™¨ï¼š
    1. è‡ªåŠ¨åŠ è½½ Cookie
    2. æ¨¡æ‹Ÿäººçš„æµè§ˆè¡Œä¸º
    3. æ‹¦æˆªç½‘ç»œè¯·æ±‚è·å–èµ„æº URL
    4. ç›´æ¥ä¸‹è½½éŸ³é¢‘/è§†é¢‘
    """
    
    def __init__(self):
        self.playwright = None
        self.browser = None
        self.context = None
    
    async def _ensure_browser(self):
        """ç¡®ä¿æµè§ˆå™¨å·²å¯åŠ¨"""
        if self.browser:
            return
        
        try:
            # Windows å¹³å°ä¿®å¤ï¼šç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„äº‹ä»¶å¾ªç¯
            import sys
            if sys.platform == 'win32':
                # è·å–å½“å‰äº‹ä»¶å¾ªç¯
                try:
                    loop = asyncio.get_running_loop()
                    # å¦‚æœå½“å‰å¾ªç¯ä¸æ˜¯ ProactorEventLoopï¼Œæˆ‘ä»¬éœ€è¦è®°å½•è­¦å‘Š
                    if not isinstance(loop, asyncio.ProactorEventLoop):
                        logger.warning("å½“å‰äº‹ä»¶å¾ªç¯ä¸æ˜¯ ProactorEventLoopï¼ŒPlaywright å¯èƒ½æ— æ³•æ­£å¸¸å·¥ä½œ")
                        # è®¾ç½®ç­–ç•¥ä»¥ä¾¿å°†æ¥çš„å¾ªç¯ä½¿ç”¨æ­£ç¡®çš„ç±»å‹
                        asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())
                except RuntimeError:
                    # æ²¡æœ‰è¿è¡Œä¸­çš„å¾ªç¯ï¼Œè®¾ç½®ç­–ç•¥
                    asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())
            
            from playwright.async_api import async_playwright
            
            self.playwright = await async_playwright().start()
            
            # å¯åŠ¨æµè§ˆå™¨ï¼ˆä½¿ç”¨ chromiumï¼Œæœ€æ¥è¿‘ Chromeï¼‰
            self.browser = await self.playwright.chromium.launch(
                headless=True,  # æ— å¤´æ¨¡å¼
                args=[
                    '--disable-blink-features=AutomationControlled',  # éšè—è‡ªåŠ¨åŒ–ç‰¹å¾
                    '--disable-dev-shm-usage',
                    '--no-sandbox',
                ]
            )
            
            # åˆ›å»ºæµè§ˆå™¨ä¸Šä¸‹æ–‡
            self.context = await self.browser.new_context(
                viewport={'width': 1920, 'height': 1080},
                user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                locale='zh-CN',
            )
            
            logger.info("âœ… æµè§ˆå™¨å¯åŠ¨æˆåŠŸ")
            
        except ImportError:
            logger.error("âŒ Playwright æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install playwright && playwright install chromium")
            raise
        except Exception as e:
            logger.error(f"âŒ æµè§ˆå™¨å¯åŠ¨å¤±è´¥: {e}")
            raise
    
    async def fetch_video_info(self, url: str) -> Tuple[Optional[str], Optional[VideoInfo]]:
        """
        è·å–è§†é¢‘ä¿¡æ¯å’Œèµ„æº URL
        
        Returns:
            (video_url, video_info) æˆ– (None, None)
        """
        await self._ensure_browser()
        
        page = await self.context.new_page()
        video_url = None
        video_info = None
        
        try:
            # æ‹¦æˆªç½‘ç»œè¯·æ±‚ï¼Œæ•è·è§†é¢‘/éŸ³é¢‘ URL
            captured_urls = []
            
            async def handle_response(response):
                url = response.url
                content_type = response.headers.get('content-type', '')
                
                # æ•è·è§†é¢‘/éŸ³é¢‘èµ„æº
                if any(ext in url for ext in ['.mp4', '.m4a', '.mp3']) or \
                   any(t in content_type for t in ['video/', 'audio/']):
                    captured_urls.append({
                        'url': url,
                        'type': content_type,
                        'size': response.headers.get('content-length', 0),
                    })
                    logger.info(f"ğŸ“¦ æ•è·èµ„æº: {url[:100]}...")
            
            page.on('response', handle_response)
            
            logger.info(f"ğŸŒ æ­£åœ¨è®¿é—®: {url}")
            
            # è®¿é—®é¡µé¢ï¼ˆä½¿ç”¨æ›´å®½æ¾çš„ç­‰å¾…ç­–ç•¥ï¼‰
            try:
                await page.goto(url, wait_until='domcontentloaded', timeout=60000)
            except Exception as e:
                logger.warning(f"é¡µé¢åŠ è½½è¶…æ—¶ï¼Œå°è¯•ç»§ç»­: {e}")
                # å³ä½¿è¶…æ—¶ä¹Ÿç»§ç»­ï¼Œå› ä¸ºå¯èƒ½å·²ç»åŠ è½½äº†éƒ¨åˆ†å†…å®¹
            
            # ç­‰å¾…é¡µé¢åŠ è½½å’Œ JavaScript æ‰§è¡Œ
            await page.wait_for_timeout(5000)
            
            # å°è¯•æå–è§†é¢‘ä¿¡æ¯
            try:
                # æ–¹æ³• 1: ä»é¡µé¢æ ‡é¢˜æå–
                title = await page.title()
                
                # æ–¹æ³• 2: ä»é¡µé¢å…ƒç´ æå–
                try:
                    desc_element = await page.query_selector('[data-e2e="video-desc"]')
                    if desc_element:
                        title = await desc_element.inner_text()
                except:
                    pass
                
                # æ–¹æ³• 3: ä» meta æ ‡ç­¾æå–
                try:
                    og_title = await page.get_attribute('meta[property="og:title"]', 'content')
                    if og_title:
                        title = og_title
                except:
                    pass
                
                # æå–ä½œè€…
                author = "æœªçŸ¥ä½œè€…"
                try:
                    author_element = await page.query_selector('[data-e2e="video-author-name"]')
                    if author_element:
                        author = await author_element.inner_text()
                except:
                    pass
                
                # æå–è§†é¢‘ ID
                video_id = re.search(r'/video/(\d+)', url)
                video_id = video_id.group(1) if video_id else 'unknown'
                
                video_info = VideoInfo(
                    video_id=video_id,
                    title=title or f"æŠ–éŸ³è§†é¢‘ {video_id}",
                    author=author,
                    duration=0,  # éœ€è¦ä»è§†é¢‘å…ƒæ•°æ®è·å–
                    url=url,
                    cover_url="",
                )
                
                logger.info(f"âœ… è§†é¢‘ä¿¡æ¯: {video_info.title} - {video_info.author}")
                
            except Exception as e:
                logger.warning(f"âš ï¸  æå–è§†é¢‘ä¿¡æ¯å¤±è´¥: {e}")
            
            # é€‰æ‹©æœ€ä½³èµ„æº URL
            if captured_urls:
                # ä¼˜å…ˆé€‰æ‹© mp4 è§†é¢‘
                video_urls = [u for u in captured_urls if '.mp4' in u['url'] or 'video/' in u['type']]
                if video_urls:
                    # é€‰æ‹©æœ€å¤§çš„
                    video_urls.sort(key=lambda x: int(x['size']) if x['size'] else 0, reverse=True)
                    video_url = video_urls[0]['url']
                    logger.info(f"âœ… é€‰æ‹©è§†é¢‘ URL: {video_url[:100]}...")
                else:
                    # æ²¡æœ‰è§†é¢‘ï¼Œé€‰æ‹©éŸ³é¢‘
                    audio_urls = [u for u in captured_urls if '.m4a' in u['url'] or '.mp3' in u['url'] or 'audio/' in u['type']]
                    if audio_urls:
                        video_url = audio_urls[0]['url']
                        logger.info(f"âœ… é€‰æ‹©éŸ³é¢‘ URL: {video_url[:100]}...")
            
            if not video_url:
                logger.error("âŒ æœªæ•è·åˆ°è§†é¢‘/éŸ³é¢‘èµ„æº")
                
                # å°è¯•ä»é¡µé¢ JavaScript ä¸­æå–
                try:
                    video_url = await self._extract_from_page_script(page)
                except Exception as e:
                    logger.error(f"ä»è„šæœ¬æå–å¤±è´¥: {e}")
            
            return video_url, video_info
            
        except Exception as e:
            logger.error(f"âŒ è·å–å¤±è´¥: {e}", exc_info=True)
            return None, None
        finally:
            await page.close()
    
    async def _extract_from_page_script(self, page) -> Optional[str]:
        """ä»é¡µé¢ JavaScript ä¸­æå–è§†é¢‘ URL"""
        try:
            # æ‰§è¡Œ JavaScript è·å–è§†é¢‘å…ƒç´ 
            video_src = await page.evaluate('''() => {
                // å°è¯•ä» video æ ‡ç­¾è·å–
                const video = document.querySelector('video');
                if (video && video.src) {
                    return video.src;
                }
                
                // å°è¯•ä» source æ ‡ç­¾è·å–
                const source = document.querySelector('video source');
                if (source && source.src) {
                    return source.src;
                }
                
                // å°è¯•ä»å…¨å±€å˜é‡è·å–
                if (window.__INITIAL_STATE__) {
                    try {
                        const state = window.__INITIAL_STATE__;
                        // æ ¹æ®å®é™…ç»“æ„è°ƒæ•´è·¯å¾„
                        if (state.video && state.video.playAddr) {
                            return state.video.playAddr;
                        }
                    } catch (e) {}
                }
                
                return null;
            }''')
            
            if video_src:
                logger.info(f"âœ… ä»é¡µé¢è„šæœ¬æå–åˆ° URL: {video_src[:100]}...")
                return video_src
            
        except Exception as e:
            logger.debug(f"ä»è„šæœ¬æå–å¤±è´¥: {e}")
        
        return None
    
    async def download_resource(self, url: str, output_path: Path) -> bool:
        """ä¸‹è½½èµ„æº"""
        try:
            await self._ensure_browser()
            
            page = await self.context.new_page()
            
            logger.info(f"ğŸ“¥ å¼€å§‹ä¸‹è½½: {url[:100]}...")
            
            # ä½¿ç”¨æµè§ˆå™¨ä¸Šä¸‹æ–‡ä¸‹è½½ï¼Œæºå¸¦å®Œæ•´çš„è¯·æ±‚å¤´å’Œ Cookie
            response = await page.request.get(url, headers={
                'Referer': 'https://www.douyin.com/',
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            }, timeout=120000)  # å¢åŠ åˆ° 120 ç§’
            
            if response.status != 200:
                logger.error(f"âŒ ä¸‹è½½å¤±è´¥: HTTP {response.status}")
                
                # å°è¯•å¤‡ç”¨æ–¹æ¡ˆï¼šç›´æ¥åœ¨é¡µé¢ä¸­ä¸‹è½½
                logger.info("ğŸ”„ å°è¯•å¤‡ç”¨ä¸‹è½½æ–¹æ¡ˆ...")
                try:
                    await page.goto(url)
                    await page.wait_for_timeout(3000)
                    
                    # è·å–é¡µé¢å†…å®¹
                    content = await page.content()
                    if len(content) > 1000:  # ç®€å•åˆ¤æ–­æ˜¯å¦æ˜¯è§†é¢‘å†…å®¹
                        output_path.parent.mkdir(parents=True, exist_ok=True)
                        with open(output_path, 'wb') as f:
                            f.write(content.encode())
                        logger.info(f"âœ… å¤‡ç”¨æ–¹æ¡ˆä¸‹è½½å®Œæˆ")
                        await page.close()
                        return True
                except Exception as e2:
                    logger.error(f"å¤‡ç”¨æ–¹æ¡ˆä¹Ÿå¤±è´¥: {e2}")
                
                await page.close()
                return False
            
            # ä¿å­˜æ–‡ä»¶
            output_path.parent.mkdir(parents=True, exist_ok=True)
            with open(output_path, 'wb') as f:
                f.write(await response.body())
            
            file_size = output_path.stat().st_size
            logger.info(f"âœ… ä¸‹è½½å®Œæˆ: {output_path} ({file_size / 1024 / 1024:.2f} MB)")
            
            await page.close()
            
            # æ£€æŸ¥æ–‡ä»¶å¤§å°æ˜¯å¦åˆç†
            if file_size < 1024:  # å°äº 1KB å¯èƒ½æ˜¯é”™è¯¯é¡µé¢
                logger.warning("âš ï¸  ä¸‹è½½çš„æ–‡ä»¶å¤ªå°ï¼Œå¯èƒ½ä¸æ˜¯æœ‰æ•ˆçš„è§†é¢‘")
                return False
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
            return False
    
    async def fetch_and_download(self, url: str) -> Tuple[Optional[Path], Optional[VideoInfo]]:
        """
        å®Œæ•´æµç¨‹: è·å–ä¿¡æ¯å¹¶ä¸‹è½½è§†é¢‘
        
        Returns:
            (video_path, video_info) æˆ– (None, None)
        """
        # 1. è·å–è§†é¢‘ URL å’Œä¿¡æ¯
        video_url, video_info = await self.fetch_video_info(url)
        
        if not video_url:
            logger.error("âŒ æ— æ³•è·å–è§†é¢‘ URL")
            return None, video_info
        
        if not video_info:
            # åˆ›å»ºåŸºæœ¬ä¿¡æ¯
            video_id = re.search(r'/video/(\d+)', url)
            video_id = video_id.group(1) if video_id else 'unknown'
            video_info = VideoInfo(
                video_id=video_id,
                title=f"æŠ–éŸ³è§†é¢‘ {video_id}",
                author="æœªçŸ¥ä½œè€…",
                duration=0,
                url=url,
                cover_url="",
            )
        
        # 2. ä¸‹è½½è§†é¢‘
        output_path = settings.temp_dir / f"{video_info.video_id}.mp4"
        success = await self.download_resource(video_url, output_path)
        
        if not success:
            return None, video_info
        
        return output_path, video_info
    
    async def close(self):
        """å…³é—­æµè§ˆå™¨"""
        if self.context:
            await self.context.close()
        if self.browser:
            await self.browser.close()
        if self.playwright:
            await self.playwright.stop()
        logger.info("ğŸ”’ æµè§ˆå™¨å·²å…³é—­")


# å…¨å±€å•ä¾‹
browser_fetcher = BrowserFetcher()
